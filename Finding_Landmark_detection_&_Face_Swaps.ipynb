{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaR3SxXRYoOw",
        "outputId": "d0010699-6e77-40ee-d96d-510e6e1bf051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-28 14:29:25--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/images.zip\n",
            "Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 52.95.150.74, 52.95.149.74, 52.95.148.162, ...\n",
            "Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|52.95.150.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-08-28 14:29:25 ERROR 404: Not Found.\n",
            "\n",
            "--2024-08-28 14:29:25--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/shape_predictor_68_face_landmarks.zip\n",
            "Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 52.95.150.74, 52.95.149.74, 52.95.148.162, ...\n",
            "Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|52.95.150.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-08-28 14:29:25 ERROR 404: Not Found.\n",
            "\n",
            "unzip:  cannot find or open images.zip, images.zip.zip or images.zip.ZIP.\n",
            "unzip:  cannot find or open shape_predictor_68_face_landmarks.zip, shape_predictor_68_face_landmarks.zip.zip or shape_predictor_68_face_landmarks.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def imshow(title = \"Image\", image = None, size =10):\n",
        "  w, h = image.shape[0], image.shape[1]\n",
        "  aspect_ratio = w/h\n",
        "  plt.figure(figsize=(size * aspect_ratio,size))\n",
        "  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "# Download and unzip our images and Facial landmark model\n",
        "!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/images.zip\n",
        "!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/shape_predictor_68_face_landmarks.zip\n",
        "!gdown --id 1O2uCujErifjvK1ziRGssaQO9khI15g6q\n",
        "!unzip -qq images.zip\n",
        "!unzip -qq shape_predictor_68_face_landmarks.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Facial Landmark Detection**"
      ],
      "metadata": {
        "id": "MRAzqqnzaDcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
        "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "class TooManyFaces(Exception):\n",
        "    pass\n",
        "\n",
        "class NoFaces(Exception):\n",
        "    pass\n",
        "\n",
        "def get_landmarks(im):\n",
        "    rects = detector(im, 1)\n",
        "\n",
        "    if len(rects) > 1:\n",
        "        raise TooManyFaces\n",
        "    if len(rects) == 0:\n",
        "        raise NoFaces\n",
        "\n",
        "    return np.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
        "\n",
        "def annotate_landmarks(im, landmarks):\n",
        "    im = im.copy()\n",
        "    for idx, point in enumerate(landmarks):\n",
        "        pos = (point[0, 0], point[0, 1])\n",
        "        cv2.putText(im, str(idx), pos,\n",
        "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
        "                    fontScale=0.4,\n",
        "\n",
        "                    color=(0, 0, 255))\n",
        "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
        "    return im\n",
        "\n",
        "image = cv2.imread('images/Trump.jpg')\n",
        "imshow('Original', image)\n",
        "landmarks = get_landmarks(image)\n",
        "image_with_landmarks = annotate_landmarks(image, landmarks)\n",
        "imshow('Result', image_with_landmarks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "hXu0tPcjY-aA",
        "outputId": "902259f3-9f2f-4ad3-f6cd-58723487f751"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fd00da407f42>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPREDICTOR_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPREDICTOR_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTooManyFaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('images/Hillary.jpg')\n",
        "imshow('Original', image)\n",
        "landmarks = get_landmarks(image)\n",
        "image_with_landmarks = annotate_landmarks(image, landmarks)\n",
        "imshow('Result', image_with_landmarks)"
      ],
      "metadata": {
        "id": "aCr24AQYaGHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Face Swapping**"
      ],
      "metadata": {
        "id": "KqOb4zL3a_38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
        "SCALE_FACTOR = 1\n",
        "FEATHER_AMOUNT = 11\n",
        "\n",
        "FACE_POINTS = list(range(17, 68))\n",
        "MOUTH_POINTS = list(range(48, 61))\n",
        "RIGHT_BROW_POINTS = list(range(17, 22))\n",
        "LEFT_BROW_POINTS = list(range(22, 27))\n",
        "RIGHT_EYE_POINTS = list(range(36, 42))\n",
        "LEFT_EYE_POINTS = list(range(42, 48))\n",
        "NOSE_POINTS = list(range(27, 35))\n",
        "JAW_POINTS = list(range(0, 17))\n",
        "\n",
        "# Points used to line up the images.\n",
        "ALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS +\n",
        "                               RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS)\n",
        "\n",
        "# Points from the second image to overlay on the first. The convex hull of each\n",
        "# element will be overlaid.\n",
        "OVERLAY_POINTS = [\n",
        "    LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
        "    NOSE_POINTS + MOUTH_POINTS,\n",
        "]\n",
        "\n",
        "# Amount of blur to use during colour correction, as a fraction of the\n",
        "# pupillary distance.\n",
        "COLOUR_CORRECT_BLUR_FRAC = 0.6\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
        "\n",
        "class TooManyFaces(Exception):\n",
        "    pass\n",
        "\n",
        "class NoFaces(Exception):\n",
        "    pass\n",
        "\n",
        "def get_landmarks(im):\n",
        "    # Returns facial landmarks as (x,y) coordinates\n",
        "    rects = detector(im, 1)\n",
        "\n",
        "    if len(rects) > 1:\n",
        "        raise TooManyFaces\n",
        "    if len(rects) == 0:\n",
        "        raise NoFaces\n",
        "\n",
        "    return np.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
        "\n",
        "\n",
        "def annotate_landmarks(im, landmarks):\n",
        "    #Overlays the landmark points on the image itself\n",
        "\n",
        "    im = im.copy()\n",
        "    for idx, point in enumerate(landmarks):\n",
        "        pos = (point[0, 0], point[0, 1])\n",
        "        cv2.putText(im, str(idx), pos,\n",
        "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
        "                    fontScale=0.4,\n",
        "                    color=(0, 0, 255))\n",
        "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
        "    return im\n",
        "\n",
        "def draw_convex_hull(im, points, color):\n",
        "    points = cv2.convexHull(points)\n",
        "    cv2.fillConvexPoly(im, points, color=color)\n",
        "\n",
        "def get_face_mask(im, landmarks):\n",
        "    im = np.zeros(im.shape[:2], dtype=np.float64)\n",
        "\n",
        "    for group in OVERLAY_POINTS:\n",
        "        draw_convex_hull(im,\n",
        "                         landmarks[group],\n",
        "                         color=1)\n",
        "\n",
        "    im = np.array([im, im, im]).transpose((1, 2, 0))\n",
        "\n",
        "    im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
        "    im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
        "\n",
        "    return im\n",
        "\n",
        "def transformation_from_points(points1, points2):\n",
        "    \"\"\"\n",
        "    Return an affine transformation [s * R | T] such that:\n",
        "        sum ||s*R*p1,i + T - p2,i||^2\n",
        "    is minimized.\n",
        "    \"\"\"\n",
        "    # Solve the procrustes problem by subtracting centroids, scaling by the\n",
        "    # standard deviation, and then using the SVD to calculate the rotation. See\n",
        "    # the following for more details:\n",
        "    #   https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem\n",
        "\n",
        "    points1 = points1.astype(np.float64)\n",
        "    points2 = points2.astype(np.float64)\n",
        "\n",
        "    c1 = np.mean(points1, axis=0)\n",
        "    c2 = np.mean(points2, axis=0)\n",
        "    points1 -= c1\n",
        "    points2 -= c2\n",
        "\n",
        "    s1 = np.std(points1)\n",
        "    s2 = np.std(points2)\n",
        "    points1 /= s1\n",
        "    points2 /= s2\n",
        "\n",
        "    U, S, Vt = np.linalg.svd(points1.T * points2)\n",
        "\n",
        "    # The R we seek is in fact the transpose of the one given by U * Vt. This\n",
        "    # is because the above formulation assumes the matrix goes on the right\n",
        "    # (with row vectors) where as our solution requires the matrix to be on the\n",
        "    # left (with column vectors).\n",
        "    R = (U * Vt).T\n",
        "\n",
        "    return np.vstack([np.hstack(((s2 / s1) * R,\n",
        "                                       c2.T - (s2 / s1) * R * c1.T)),\n",
        "                         np.matrix([0., 0., 1.])])\n",
        "\n",
        "def read_im_and_landmarks(image):\n",
        "    im = image\n",
        "    im = cv2.resize(im,None,fx=1, fy=1, interpolation = cv2.INTER_LINEAR)\n",
        "    im = cv2.resize(im, (im.shape[1] * SCALE_FACTOR,\n",
        "                         im.shape[0] * SCALE_FACTOR))\n",
        "    s = get_landmarks(im)\n",
        "\n",
        "    return im, s\n",
        "\n",
        "def warp_im(im, M, dshape):\n",
        "    output_im = np.zeros(dshape, dtype=im.dtype)\n",
        "    cv2.warpAffine(im,\n",
        "                   M[:2],\n",
        "                   (dshape[1], dshape[0]),\n",
        "                   dst=output_im,\n",
        "                   borderMode=cv2.BORDER_TRANSPARENT,\n",
        "                   flags=cv2.WARP_INVERSE_MAP)\n",
        "    return output_im\n",
        "\n",
        "def correct_colours(im1, im2, landmarks1):\n",
        "    blur_amount = COLOUR_CORRECT_BLUR_FRAC * np.linalg.norm(\n",
        "                              np.mean(landmarks1[LEFT_EYE_POINTS], axis=0) -\n",
        "                              np.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
        "    blur_amount = int(blur_amount)\n",
        "    if blur_amount % 2 == 0:\n",
        "        blur_amount += 1\n",
        "    im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0)\n",
        "    im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0)\n",
        "\n",
        "    # Avoid divide-by-zero errors.\n",
        "    im2_blur += (128 * (im2_blur <= 1.0)).astype(im2_blur.dtype)\n",
        "\n",
        "    return (im2.astype(np.float64) * im1_blur.astype(np.float64) /\n",
        "                                                im2_blur.astype(np.float64))\n",
        "\n",
        "\n",
        "def swappy(image1, image2):\n",
        "\n",
        "    im1, landmarks1 = read_im_and_landmarks(image1)\n",
        "    im2, landmarks2 = read_im_and_landmarks(image2)\n",
        "\n",
        "    M = transformation_from_points(landmarks1[ALIGN_POINTS],\n",
        "                                   landmarks2[ALIGN_POINTS])\n",
        "\n",
        "    mask = get_face_mask(im2, landmarks2)\n",
        "    warped_mask = warp_im(mask, M, im1.shape)\n",
        "    combined_mask = np.max([get_face_mask(im1, landmarks1), warped_mask],\n",
        "                              axis=0)\n",
        "\n",
        "    warped_im2 = warp_im(im2, M, im1.shape)\n",
        "    warped_corrected_im2 = correct_colours(im1, warped_im2, landmarks1)\n",
        "\n",
        "    output_im = im1 * (1.0 - combined_mask) + warped_corrected_im2 * combined_mask\n",
        "    cv2.imwrite('output.jpg', output_im)\n",
        "    image = cv2.imread('output.jpg')\n",
        "    return image\n",
        "\n",
        "\n",
        "## Enter the paths to your input images here\n",
        "image1 = cv2.imread('images/Hillary.jpg')\n",
        "image2 = cv2.imread('images/Trump.jpg')\n",
        "\n",
        "swapped = swappy(image1, image2)\n",
        "imshow('Face Swap 1', swapped)\n",
        "\n",
        "swapped = swappy(image2, image1)\n",
        "imshow('Face Swap 2', swapped)"
      ],
      "metadata": {
        "id": "9NtmhkCUaFIV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}